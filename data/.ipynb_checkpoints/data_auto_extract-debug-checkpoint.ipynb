{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8866c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2022\n",
    "For Friktion Labs\n",
    "Done by: MordantBlack (enfamil#3658)\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import schedule\n",
    "import time\n",
    "import threading\n",
    "import glob\n",
    "import os.path\n",
    "from pycoingecko import CoinGeckoAPI\n",
    "\n",
    "def run_query(query):  # A simple function to use requests.post to make the API call.\n",
    "    headers = {'X-API-KEY': 'BQYCaXaMZlqZrPCSQVsiJrKtxKRVcSe4'}\n",
    "    request = requests.post('https://graphql.bitquery.io/', json={'query': query}, headers=headers)\n",
    "    if request.status_code == 200:\n",
    "        return request.json()\n",
    "    else:\n",
    "        raise Exception('Query failed and return code is {}.{}'.format(request.status_code, query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad77ba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_volt_data(csv_name):\n",
    "    \n",
    "    # search for existing csv files in data folder\n",
    "    # REMEMBER TO CHANGE PATH DIRECTORY!\n",
    "    csv_files = glob.glob(os.path.join('/Users/.../data', csv_name))\n",
    "    \n",
    "    # if files are non-existent, to create them with initial date range from 17-30 Dec 21\n",
    "    if not csv_files:\n",
    "        print(csv_name + \" missing\")\n",
    "        query_date = '\"2022-02-14\", \"2022-02-15\"'\n",
    "        if csv_name == 'volt01_master.csv':\n",
    "            extract_volt01_uu(query_date, csv_files)\n",
    "            action = \"Volt 01 Unique Users & Tx Size\"\n",
    "        elif csv_name == 'volt01_master_wd.csv':\n",
    "            extract_volt01_wd(query_date, csv_files)\n",
    "            action = \"Volt 01 Withdrawals\"\n",
    "        elif csv_name == 'volt02_master.csv':    \n",
    "            extract_volt02_uu(query_date, csv_files)\n",
    "            action = \"Volt 02 Unique Users & Tx Size\"\n",
    "        elif csv_name == 'volt02_master_wd.csv':\n",
    "            extract_volt02_wd(query_date, csv_files)\n",
    "            action = \"Volt 02 Withdrawals\"\n",
    "        \n",
    "        print(datetime.utcnow().strftime('%Y-%m-%d , %H:%M:%S') + \" - Running query of \" + action + \"...\")\n",
    "    \n",
    "    else:\n",
    "        print(csv_name + \" found\")\n",
    "        dataframe = pd.read_csv(csv_name, index_col=0, parse_dates=True)\n",
    "        \n",
    "        # If csv found, calculate date range to retrieve updated data\n",
    "        dataframe.index = pd.to_datetime(dataframe['date'], format = '%Y-%m-%d')\n",
    "        # get 1 day before current date. This ensures that one full day of volt transactions are \n",
    "        # captured on solscan\n",
    "        utc_date_bef = datetime.utcnow().date() - timedelta(days=1) # solscan is in UTC\n",
    "        # df max date + 1\n",
    "        start_date_query = dataframe.index.max().date() + timedelta(days=1)\n",
    "        # if df max date is less than utc date, \n",
    "        if start_date_query < utc_date_bef:\n",
    "            query_date =  '\"' + start_date_query.strftime('%Y-%m-%d') + '\"' + ',' + '\"' + utc_date_bef.strftime('%Y-%m-%d') + '\"'\n",
    "            if csv_name == 'volt01_master.csv':\n",
    "                extract_volt01_uu(query_date, csv_files)\n",
    "                action = \"Volt 01 Unique Users & Tx size\"\n",
    "            elif csv_name == 'volt01_master_wd.csv':\n",
    "                extract_volt01_wd(query_date, csv_files)\n",
    "                action = \"Volt 01 Withdrawals\"\n",
    "            elif csv_name == 'volt02_master.csv':    \n",
    "                extract_volt02_uu(query_date, csv_files)\n",
    "                action = \"Volt 02 Unique Users & Tx size\"\n",
    "            elif csv_name == 'volt02_master_wd.csv':    \n",
    "                extract_volt02_wd(query_date, csv_files)\n",
    "                action = \"Volt 02 Unique Users & Tx size\"\n",
    "            print(datetime.utcnow().strftime('%Y-%m-%d , %H:%M:%S') + \" - Running query of \" + action + \"...\")\n",
    "            \n",
    "        else:\n",
    "            print(datetime.utcnow().strftime('%Y-%m-%d , %H:%M:%S') +  \" - No new data found, running query again in 24 hours.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89b4e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_volt01_uu(query_date, csv_files):\n",
    "    # The GraphQL query - Volt01 Call\n",
    "    # 16 Dec 2021 - BTC Volt 01 Call - 3BjcHXvyzMsjmeqE2qFLx45K4XFx3JPiyRnjJiF5MAHt\n",
    "    # 17 Dec 2021 - SOL Volt 01 Call - 4Hnh1UCC6HLzx9NaGKnTVHR2bANcRrhydumdHCnrT3i2\n",
    "    # mSOL Volt 01 Call - 6UA3yn28XecAHLTwoCtjfzy3WcyQj1x13bxnH8urUiKt\n",
    "    # ETH Volt 01 Call - GjnoPUjQiEUYWuKAbMax2cM1Eony8Yutc133wuSun9hS\n",
    "    # FTT Volt 01 Call - 7wDh4VCTPwx41kvbLE6fkFgMEjnqw7NpGJvQtNabCm2B\n",
    "    # SRM Volt 01 Call - 5SLqZSywodLS8ih6U2AAioZrxpgR149hR8SApmCB7r5X\n",
    "    # MNGO Volt 01 Call - 4sTuzTYfcE2NF7zy6Sy8XhVcNLa6JQSLrx3roy97n4sD\n",
    "    # scnSOL Volt 01 Call - 5VmdHqvRMbXivuC34w4Hux9zb1y9moiBEQmXDrTR1kV\n",
    "    # SBR Volt 01 Call - DPMCwE9z9jXaDVDti5aKhdgCWGgsvioz6ZvB9eZjH7UE\n",
    "    # LUNA Volt 01 Call - 95sn4kgeJnnBfRCD8S2quu4HS9Y6vb7JDuXrarnmEjYE\n",
    "    \n",
    "    query = \"\"\"\n",
    "    query{\n",
    "    solana(network: solana) {\n",
    "    transfers(\n",
    "      date: {between: [\"\"\"+ query_date +\"\"\"]}\n",
    "      transferType: {is: transfer}\n",
    "      currency: {in: [\"SOL\", \"BTC\", \"mSOL\", \"ETH\", \"FTT\", \"SRM\", \"MNGO\", \"scnSOL\", \"SBR\", \"LUNA\", \"RAY\"]}\n",
    "      any: [{receiverAddress: {in: [\n",
    "        \"Hxtb6APfNtf9m8jJjh7uYp8fCTGr9aeHxBSfiPqCrV6G\",\n",
    "        \"DA1M8mw7GnPNKU9ReANtHPQyuVzKZtsuuSbCyc2uX2du\",\n",
    "        \"6asST5hurmxJ8uFvh7ZRWkrMfSEzjEAJ4DNR1is3G6eH\",\n",
    "        \"FThcy5XXvab5u3jbA6NjWKdMNiCSV3oY5AAkvEvpa8wp\",\n",
    "        \"7KqHFuUksvNhrWgoacKkqyp2RwfBNdypCYgK9nxD1d6K\",\n",
    "        \"2P427N5sYcEXvZAZwqNzjXEHsBMESQoLyjNquTSmGPMb\",\n",
    "        \"B3yakZxwomkmnCxRr8ZmQtiWgtxtVBuCREDFDdAvcCVQ\",\n",
    "        \"A5MpyajTy6hdsg3S2em5ukcgY1ZBhxTxEKv8BgHajv1A\",\n",
    "        \"BH7Jg3f97FyeGxsPR7FFskvfqGiaLeUnJ9Ksda53Jj8h\",\n",
    "        \"5oV1Yf8q1oQgPYuHjepjmKFuaG2Wng9dzTqbSWhU5W2X\",\n",
    "        \"A6XsYxGj9wpqUZG81XwgQJ2zJ3efCbuWSQfnkHqUSmdM\"]}}]\n",
    "    ) {\n",
    "      amount\n",
    "      currency {\n",
    "        symbol\n",
    "      }\n",
    "      date {\n",
    "        date\n",
    "      }\n",
    "      transaction {\n",
    "        signer\n",
    "      }\n",
    "      sender {\n",
    "        address\n",
    "      }\n",
    "    }\n",
    "    }\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    result = run_query(query)\n",
    "    # convert GraphQL json to pandas dataframe\n",
    "    df = pd.json_normalize(result['data']['solana']['transfers'])\n",
    "    # relabel columns\n",
    "    df = df.rename(columns={\"date.date\": \"date\", \"currency.symbol\": \"asset\", \"transaction.signer\":\"signer\",\"sender.address\":\"sender\"})\n",
    "    # IMPORTANT - if transaction signer & receiver is diff, drop row\n",
    "    df = df.query(\"signer == sender\").reset_index(drop=True)\n",
    "    \n",
    "    if not csv_files:\n",
    "        df.to_csv(\"volt01_master.csv\")\n",
    "        print(\"Master sheet created with dates between \" + query_date)\n",
    "    else:\n",
    "        df.to_csv(\"volt01_master.csv\", mode='a', header=False)\n",
    "        print(\"Master sheet created with dates Updated!\") \n",
    "    \n",
    "    # read csv\n",
    "    df_uu = pd.read_csv(\"volt01_master.csv\", index_col=0)\n",
    "    df_ts = pd.read_csv(\"volt01_master.csv\", index_col=0)\n",
    "\n",
    "    #---------------- UNIQUE USERS ----------------------------\n",
    "    df_uu = df_uu.groupby(['asset', 'date']).size().reset_index(name='count')\n",
    "    # remove duplicated rows if any\n",
    "    df_uu.drop_duplicates(keep='first',inplace=True)\n",
    "    # save Unique Users df to csv\n",
    "    df_uu.to_csv(\"volt01_uu.csv\")\n",
    "    print(\"volt01_uu.csv updated with date range \" + query_date)\n",
    "    \n",
    "    #---------------- TRANSACTION SIZE ----------------------------\n",
    "    # sum up amount according to sender addresses by asset grp\n",
    "    agg_functions = {'amount': 'sum'}\n",
    "    df_ts = df_ts.groupby(['asset','sender']).agg(agg_functions).reset_index()\n",
    "    # get average size of each asset grp\n",
    "    agg_functions_2 = {'amount': 'mean'}\n",
    "    df_ts = df_ts.groupby(['asset']).agg(agg_functions_2).reset_index()\n",
    "\n",
    "    agg_functions = {'count': 'sum'}\n",
    "    df_uu = df_uu.groupby(['asset']).agg(agg_functions).reset_index()\n",
    "    df_merge = pd.merge(df_ts, df_uu, on=\"asset\")\n",
    "\n",
    "    # get asset prices\n",
    "    cg = CoinGeckoAPI()\n",
    "    # SOL, BTC, mSOL, ETH, FTT, SRM\", \"MNGO\", \"scnSOL\", \"SBR\", \"LUNA\", \"RAY\"\n",
    "    asset_price = cg.get_price(ids='solana, bitcoin, msol, ethereum, ftx-token, serum, mango-markets, socean-staked-sol, saber, terra-luna, raydium', vs_currencies='usd')\n",
    "    df_price = pd.DataFrame(asset_price)\n",
    "    df_price = df_price.rename(columns={\"solana\": \"SOL\", \"bitcoin\": \"BTC\", \"msol\": \"mSOL\", \n",
    "                         \"ethereum\": \"ETH\", \"ftx-token\": \"FTT\", \"serum\": \"SRM\", \n",
    "                         \"mango-markets\": \"MNGO\", \"socean-staked-sol\": \"scnSOL\", \n",
    "                         \"saber\": \"SBR\", \"terra-luna\": \"LUNA\", \"raydium\": \"RAY\"})\n",
    "    df_price = df_price.T\n",
    "    df_price = df_price.rename_axis('asset').reset_index()\n",
    "    # Concatenate 2 tables tgt aligning assets\n",
    "    final_df = pd.merge(df_merge, df_price, on='asset')\n",
    "    # Get average transaction size in USD\n",
    "    final_df[\"tx_size\"] = final_df[\"amount\"] * final_df[\"usd\"]\n",
    "    final_df.sort_values(by=['tx_size'], inplace=True)\n",
    "    final_df = final_df.fillna(0)\n",
    "    # save Tx Size df to csv\n",
    "    final_df.to_csv(\"volt01_ts.csv\")\n",
    "    print(\"volt01_ts.csv updated with date range \" + query_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e2b269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------- WITHDRAWALS per Epoch from Volt 01 ------------------------------- \n",
    "def extract_volt01_wd(query_date, csv_files):\n",
    "    # currency: {in: [\"SOL\", \"BTC\", \"mSOL\", \"ETH\", \"FTT\", \"SRM\", \"MNGO\", \"scnSOL\", \"SBR\", \"LUNA\", \"RAY\"]}\n",
    "\n",
    "    query = \"\"\"\n",
    "        query{\n",
    "        solana(network: solana) {\n",
    "        transfers(\n",
    "          date: {between: [\"\"\"+ query_date +\"\"\"]}\n",
    "          transferType: {is: transfer}\n",
    "          any: [{senderAddress: {in: [\n",
    "            \"Hxtb6APfNtf9m8jJjh7uYp8fCTGr9aeHxBSfiPqCrV6G\",\n",
    "            \"DA1M8mw7GnPNKU9ReANtHPQyuVzKZtsuuSbCyc2uX2du\",\n",
    "            \"6asST5hurmxJ8uFvh7ZRWkrMfSEzjEAJ4DNR1is3G6eH\",\n",
    "            \"FThcy5XXvab5u3jbA6NjWKdMNiCSV3oY5AAkvEvpa8wp\",\n",
    "            \"7KqHFuUksvNhrWgoacKkqyp2RwfBNdypCYgK9nxD1d6K\",\n",
    "            \"2P427N5sYcEXvZAZwqNzjXEHsBMESQoLyjNquTSmGPMb\",\n",
    "            \"B3yakZxwomkmnCxRr8ZmQtiWgtxtVBuCREDFDdAvcCVQ\",\n",
    "            \"A5MpyajTy6hdsg3S2em5ukcgY1ZBhxTxEKv8BgHajv1A\",\n",
    "            \"BH7Jg3f97FyeGxsPR7FFskvfqGiaLeUnJ9Ksda53Jj8h\",\n",
    "            \"5oV1Yf8q1oQgPYuHjepjmKFuaG2Wng9dzTqbSWhU5W2X\",\n",
    "            \"A6XsYxGj9wpqUZG81XwgQJ2zJ3efCbuWSQfnkHqUSmdM\"]}}]\n",
    "        ) {\n",
    "          amount\n",
    "          currency {\n",
    "            symbol\n",
    "          }\n",
    "          block {\n",
    "            timestamp {\n",
    "              iso8601\n",
    "            }\n",
    "          }\n",
    "          transaction {\n",
    "            signer\n",
    "          }\n",
    "          receiver {\n",
    "            address\n",
    "          }\n",
    "          sender {\n",
    "            address\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    result = run_query(query)\n",
    "    # convert GraphQL json to pandas dataframe\n",
    "    df = pd.json_normalize(result['data']['solana']['transfers'])\n",
    "    df = df.rename(columns={\"block.timestamp.iso8601\": \"date\", \"currency.symbol\": \"symbol\", \n",
    "                            \"transaction.signer\":\"signer\",\"receiver.address\":\"receiver\",\n",
    "                            \"sender.address\":\"asset\"})\n",
    "    # if transaction signer & receiver is diff, drop row\n",
    "    df = df.query(\"signer == receiver\")\n",
    "    \n",
    "    if not csv_files:\n",
    "        df.to_csv(\"volt01_master_wd.csv\")\n",
    "        print(\"Master sheet withdrawal created with dates between \" + query_date)\n",
    "    else:\n",
    "        df.to_csv(\"volt01_master_wd.csv\", mode='a', header=False)\n",
    "        print(\"Master sheet withdrawal created with dates Updated!\") \n",
    "    \n",
    "    df_wd = pd.read_csv(\"volt01_master_wd.csv\", index_col=0)\n",
    "    \n",
    "    # assign asset label over sender address\n",
    "    asset_conditions = [\n",
    "            (df_wd['asset'] == \"Hxtb6APfNtf9m8jJjh7uYp8fCTGr9aeHxBSfiPqCrV6G\"),\n",
    "            (df_wd['asset'] == \"DA1M8mw7GnPNKU9ReANtHPQyuVzKZtsuuSbCyc2uX2du\"),\n",
    "            (df_wd['asset'] == \"6asST5hurmxJ8uFvh7ZRWkrMfSEzjEAJ4DNR1is3G6eH\"),\n",
    "            (df_wd['asset'] == \"FThcy5XXvab5u3jbA6NjWKdMNiCSV3oY5AAkvEvpa8wp\"),\n",
    "            (df_wd['asset'] == \"7KqHFuUksvNhrWgoacKkqyp2RwfBNdypCYgK9nxD1d6K\"),\n",
    "            (df_wd['asset'] == \"2P427N5sYcEXvZAZwqNzjXEHsBMESQoLyjNquTSmGPMb\"),\n",
    "            (df_wd['asset'] == \"B3yakZxwomkmnCxRr8ZmQtiWgtxtVBuCREDFDdAvcCVQ\"),\n",
    "            (df_wd['asset'] == \"A5MpyajTy6hdsg3S2em5ukcgY1ZBhxTxEKv8BgHajv1A\"),\n",
    "            (df_wd['asset'] == \"BH7Jg3f97FyeGxsPR7FFskvfqGiaLeUnJ9Ksda53Jj8h\"),\n",
    "            (df_wd['asset'] == \"5oV1Yf8q1oQgPYuHjepjmKFuaG2Wng9dzTqbSWhU5W2X\"),\n",
    "            (df_wd['asset'] == \"A6XsYxGj9wpqUZG81XwgQJ2zJ3efCbuWSQfnkHqUSmdM\")\n",
    "        ]\n",
    "    \n",
    "    # relabeling addresses as asset labels\n",
    "    asset_Categories = [\"SOL\", \"BTC\", \"mSOL\", \"ETH\", \"FTT\", \"SRM\", \"MNGO\", \"scnSOL\", \"SBR\", \"LUNA\", \"RAY\"]\n",
    "    df_wd['asset'] = np.select(asset_conditions, asset_Categories)\n",
    "    # drop redundant columns\n",
    "    df_wd.drop(['symbol', 'signer', 'receiver'], axis=1, inplace=True)\n",
    "    df_wd['date'] = pd.to_datetime(df_wd['date'], format = '%Y-%m-%dT%H:%M:%SZ')\n",
    "    # groupby date in grps of 1 week & sum amount of each asset\n",
    "    df_wd = df_wd.groupby([pd.Grouper(key='date', freq='7D'),'asset']).sum()\n",
    "    # Adding Epoch labels per week\n",
    "    df_wd = df_wd.reset_index()\n",
    "    date_df = pd.DataFrame(df_wd['date'].unique())\n",
    "    epoch_lst = []\n",
    "    for i in range(len(date_df)):\n",
    "        epoch_lst.append('Epoch ' + str(i + 1) + ' - ' + str(date_df[0][i].strftime('%Y-%m-%d')))\n",
    "    \n",
    "    epoch_df = pd.DataFrame(list(zip(date_df[0], epoch_lst)), columns =['date', 'epoch'])\n",
    "    merge_on_date = pd.merge(epoch_df, df_wd[[\"date\",\"asset\",\"amount\"]], on=\"date\")\n",
    "    # get price of assets\n",
    "    cg = CoinGeckoAPI()\n",
    "\n",
    "    # SOL, BTC, mSOL, ETH, FTT, SRM\", \"MNGO\", \"scnSOL\", \"SBR\", \"LUNA\", \"RAY\"\n",
    "    asset_price = cg.get_price(ids='solana, bitcoin, msol, ethereum, ftx-token, serum, mango-markets, socean-staked-sol, saber, terra-luna, raydium', vs_currencies='usd')\n",
    "    df_price = pd.DataFrame(asset_price)\n",
    "    df_price = df_price.rename(columns={\"solana\": \"SOL\", \"bitcoin\": \"BTC\", \"msol\": \"mSOL\", \n",
    "                             \"ethereum\": \"ETH\", \"ftx-token\": \"FTT\", \"serum\": \"SRM\", \n",
    "                             \"mango-markets\": \"MNGO\", \"socean-staked-sol\": \"scnSOL\", \n",
    "                             \"saber\": \"SBR\", \"terra-luna\": \"LUNA\", \"raydium\": \"RAY\"})\n",
    "\n",
    "    df_price = df_price.T\n",
    "    # rename axis & merge with other df at asset column\n",
    "    df_price = df_price.rename_axis('asset').reset_index()\n",
    "    # concat both dataframes tgt\n",
    "    merge = pd.merge(df_price, merge_on_date[[\"epoch\",\"asset\",\"amount\"]], on=\"asset\")\n",
    "    merge['amt_usd'] = merge['amount'] * merge['usd']\n",
    "    \n",
    "    # save df to csv\n",
    "    merge.to_csv(\"volt01_wd.csv\")\n",
    "    print(\"volt01_wd.csv Updated with date range \" + query_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa9a10e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_volt02_uu(query_date, csv_files):\n",
    "    \n",
    "    # Volt 02 SOL Put: 6Nkc8MEiz3WLz1xthYitmSuy3NGwn7782upRHo2iFmXK\n",
    "    # Volt 02 BTC Put: GrB6vbG2WP7eEnbwgxUbBGRMeXYq139jo2o9oW8cNK8f\n",
    "    # Volt 02 SOL Put (tsUSDC): AQRGh6PU7LzDHvvoPNS7wVVQaCBeftw9kVDAnvuEjbs8\n",
    "    # Volt 02 ETH Put: EA29Xf3HGMtYziw7UKZDUKby7gkoCbXwmiNKwc7z54Ax\n",
    "    # Volt 02 LUNA Put: 5kA7FPiB3t2X5s65dK1AoEu5asDjC5d7f5vaB4iY2yrj\n",
    "    # Volt 02 MNGO Put: CVrRw6VtxSjokm2tKmaS5RCuoc9EFjN4wEoov6f2PST6\n",
    "    query = \"\"\"\n",
    "    query{\n",
    "        solana(network: solana) {\n",
    "        transfers(\n",
    "          transferType: {is: transfer}\n",
    "          date: {between: [\"\"\"+ query_date +\"\"\"]}\n",
    "          any: [{receiverAddress: {in: [\n",
    "            \"6Nkc8MEiz3WLz1xthYitmSuy3NGwn7782upRHo2iFmXK\",\n",
    "            \"GrB6vbG2WP7eEnbwgxUbBGRMeXYq139jo2o9oW8cNK8f\",\n",
    "            \"AQRGh6PU7LzDHvvoPNS7wVVQaCBeftw9kVDAnvuEjbs8\",\n",
    "            \"EA29Xf3HGMtYziw7UKZDUKby7gkoCbXwmiNKwc7z54Ax\",\n",
    "            \"5kA7FPiB3t2X5s65dK1AoEu5asDjC5d7f5vaB4iY2yrj\",\n",
    "            \"CVrRw6VtxSjokm2tKmaS5RCuoc9EFjN4wEoov6f2PST6\"]}}]\n",
    "        ) {\n",
    "          amount\n",
    "          currency {\n",
    "            symbol\n",
    "            address\n",
    "          }\n",
    "          date {\n",
    "            date\n",
    "          }\n",
    "          transaction {\n",
    "            signer\n",
    "          }\n",
    "          sender {\n",
    "            address\n",
    "          }\n",
    "          receiver {\n",
    "            address\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    result = run_query(query)\n",
    "    # convert GraphQL json to pandas dataframe\n",
    "    df = pd.json_normalize(result['data']['solana']['transfers'])\n",
    "\n",
    "    df = df.rename(columns={\"date.date\": \"date\", \"currency.symbol\": \"symbol\", \n",
    "                            \"transaction.signer\":\"signer\", \"currency.address\":\"cash\",\n",
    "                            \"sender.address\":\"sender\", \"receiver.address\":\"asset\"})\n",
    "    # if transaction signer & receiver is diff, drop row\n",
    "    df = df.query(\"signer == sender\").reset_index(drop=True)\n",
    "\n",
    "    # assign asset label over address\n",
    "    # UST: 9vMJfxuKxXBoEa7rM12mYLMwTacLMLDJqHozw96WQL8i\n",
    "    # tsUSDC: Cvvh8nsKZet59nsDDo3orMa3rZnPWQhpgrMCVcRDRgip\n",
    "    # USDC: EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v\n",
    "    cash_conditions = [\n",
    "            (df['cash'] == \"9vMJfxuKxXBoEa7rM12mYLMwTacLMLDJqHozw96WQL8i\"),\n",
    "            (df['cash'] == \"Cvvh8nsKZet59nsDDo3orMa3rZnPWQhpgrMCVcRDRgip\"),\n",
    "            (df['cash'] == \"EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v\"),\n",
    "        ]\n",
    "\n",
    "    # relabeling addresses as asset labels\n",
    "    cash_Categories = [\"UST\", \"tsUSDC\", \"USDC\"]\n",
    "    df['cash'] = np.select(cash_conditions, cash_Categories)\n",
    "    # remove non-stablecoin assets\n",
    "    df = df[df[\"cash\"] != \"0\"]\n",
    "\n",
    "    # Volt 02 SOL Put: 6Nkc8MEiz3WLz1xthYitmSuy3NGwn7782upRHo2iFmXK\n",
    "    # Volt 02 BTC Put: GrB6vbG2WP7eEnbwgxUbBGRMeXYq139jo2o9oW8cNK8f\n",
    "    # Volt 02 SOL Put (tsUSDC): AQRGh6PU7LzDHvvoPNS7wVVQaCBeftw9kVDAnvuEjbs8\n",
    "    # Volt 02 ETH Put: EA29Xf3HGMtYziw7UKZDUKby7gkoCbXwmiNKwc7z54Ax\n",
    "    # Volt 02 LUNA Put: 5kA7FPiB3t2X5s65dK1AoEu5asDjC5d7f5vaB4iY2yrj\n",
    "    # Volt 02 MNGO Put: CVrRw6VtxSjokm2tKmaS5RCuoc9EFjN4wEoov6f2PST6\n",
    "\n",
    "    asset_conditions = [\n",
    "            (df['asset'] == \"6Nkc8MEiz3WLz1xthYitmSuy3NGwn7782upRHo2iFmXK\"),\n",
    "            (df['asset'] == \"GrB6vbG2WP7eEnbwgxUbBGRMeXYq139jo2o9oW8cNK8f\"),\n",
    "            (df['asset'] == \"AQRGh6PU7LzDHvvoPNS7wVVQaCBeftw9kVDAnvuEjbs8\"),\n",
    "            (df['asset'] == \"EA29Xf3HGMtYziw7UKZDUKby7gkoCbXwmiNKwc7z54Ax\"),\n",
    "            (df['asset'] == \"5kA7FPiB3t2X5s65dK1AoEu5asDjC5d7f5vaB4iY2yrj\"),\n",
    "            (df['asset'] == \"CVrRw6VtxSjokm2tKmaS5RCuoc9EFjN4wEoov6f2PST6\"),\n",
    "        ]\n",
    "\n",
    "    # relabeling addresses as asset labels\n",
    "    asset_Categories = [\"SOL\", \"BTC\", \"SOL (tsUSDC)\", \"ETH\", \"LUNA\", \"MNGO\"]\n",
    "    df['asset'] = np.select(asset_conditions, asset_Categories)\n",
    "\n",
    "    if not csv_files:\n",
    "        df.to_csv(\"volt02_master.csv\")\n",
    "        print(\"Volt 02 Master sheet created with dates between \" + query_date)\n",
    "    else:\n",
    "        df.to_csv(\"volt02_master.csv\", mode='a', header=False)\n",
    "        print(\"Volt 02 Master sheet created with dates Updated!\") \n",
    "\n",
    "    # # read csv\n",
    "    df_uu = pd.read_csv(\"volt02_master.csv\", index_col=0)\n",
    "    df_ts = pd.read_csv(\"volt02_master.csv\", index_col=0)\n",
    "\n",
    "    #---------------- UNIQUE USERS ----------------------------\n",
    "    df_uu = df_uu.groupby(['asset', 'date']).size().reset_index(name='count')\n",
    "    # remove duplicated rows if any\n",
    "    df_uu.drop_duplicates(keep='first',inplace=True)\n",
    "    # save unique users df to csv\n",
    "    df_uu.to_csv(\"volt02_uu.csv\")\n",
    "    print(\"volt02_uu.csv updated with date range \" + query_date)\n",
    "\n",
    "    #---------------- TRANSACTION SIZE ----------------------------\n",
    "    # sum up amount according to sender addresses by asset grp\n",
    "    agg_functions = {'amount': 'sum'}\n",
    "    df_ts = df_ts.groupby(['asset','sender']).agg(agg_functions).reset_index()\n",
    "    # get average size of each asset grp\n",
    "    agg_functions_2 = {'amount': 'mean'}\n",
    "    df_ts = df_ts.groupby(['asset']).agg(agg_functions_2).reset_index()\n",
    "\n",
    "    agg_functions = {'count': 'sum'}\n",
    "    df_uu = df_uu.groupby(['asset']).agg(agg_functions).reset_index()\n",
    "    df_merge = pd.merge(df_ts, df_uu, on=\"asset\")\n",
    "\n",
    "    df_merge['tx_size'] = df_merge[\"amount\"] * 1\n",
    "    # save Tx Size df to csv\n",
    "    df_merge.to_csv(\"volt02_ts.csv\")\n",
    "    print(\"volt02_ts.csv updated with date range \" + query_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f678b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------- WITHDRAWALS per Epoch from Volt 02 ------------------------------- \n",
    "def extract_volt02_wd(query_date, csv_files):\n",
    "    # Volt 02 SOL Put: 6Nkc8MEiz3WLz1xthYitmSuy3NGwn7782upRHo2iFmXK\n",
    "    # Volt 02 BTC Put: GrB6vbG2WP7eEnbwgxUbBGRMeXYq139jo2o9oW8cNK8f\n",
    "    # Volt 02 SOL Put (tsUSDC): AQRGh6PU7LzDHvvoPNS7wVVQaCBeftw9kVDAnvuEjbs8\n",
    "    # Volt 02 ETH Put: EA29Xf3HGMtYziw7UKZDUKby7gkoCbXwmiNKwc7z54Ax\n",
    "    # Volt 02 LUNA Put: 5kA7FPiB3t2X5s65dK1AoEu5asDjC5d7f5vaB4iY2yrj\n",
    "    # Volt 02 MNGO Put: CVrRw6VtxSjokm2tKmaS5RCuoc9EFjN4wEoov6f2PST6\n",
    "\n",
    "    query = \"\"\"\n",
    "        query{\n",
    "        solana(network: solana) {\n",
    "        transfers(\n",
    "          date: {between: [\"\"\"+ query_date +\"\"\"]}\n",
    "          transferType: {is: transfer}\n",
    "          any: [{senderAddress: {in: [\n",
    "            \"6Nkc8MEiz3WLz1xthYitmSuy3NGwn7782upRHo2iFmXK\",\n",
    "            \"GrB6vbG2WP7eEnbwgxUbBGRMeXYq139jo2o9oW8cNK8f\",\n",
    "            \"AQRGh6PU7LzDHvvoPNS7wVVQaCBeftw9kVDAnvuEjbs8\",\n",
    "            \"EA29Xf3HGMtYziw7UKZDUKby7gkoCbXwmiNKwc7z54Ax\",\n",
    "            \"5kA7FPiB3t2X5s65dK1AoEu5asDjC5d7f5vaB4iY2yrj\",\n",
    "            \"CVrRw6VtxSjokm2tKmaS5RCuoc9EFjN4wEoov6f2PST6\"]}}]\n",
    "        ) {\n",
    "          amount\n",
    "          currency {\n",
    "            symbol\n",
    "            address\n",
    "          }\n",
    "          block {\n",
    "            timestamp {\n",
    "              iso8601\n",
    "            }\n",
    "          }\n",
    "          transaction {\n",
    "            signer\n",
    "          }\n",
    "          receiver {\n",
    "            address\n",
    "          }\n",
    "          sender {\n",
    "            address\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    result = run_query(query)\n",
    "    # convert GraphQL json to pandas dataframe\n",
    "    df = pd.json_normalize(result['data']['solana']['transfers'])\n",
    "    df = df.rename(columns={\"block.timestamp.iso8601\": \"date\", \"currency.symbol\": \"symbol\", \n",
    "                            \"transaction.signer\":\"signer\", \"currency.address\":\"cash\",\n",
    "                            \"receiver.address\":\"receiver\", \"sender.address\":\"asset\"})\n",
    "    # if transaction signer & receiver is diff, drop row\n",
    "    df = df.query(\"signer == receiver\").reset_index(drop=True)\n",
    "    # assign asset label over address\n",
    "    # UST: 9vMJfxuKxXBoEa7rM12mYLMwTacLMLDJqHozw96WQL8i\n",
    "    # tsUSDC: Cvvh8nsKZet59nsDDo3orMa3rZnPWQhpgrMCVcRDRgip\n",
    "    # USDC: EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v\n",
    "    cash_conditions = [\n",
    "            (df['cash'] == \"9vMJfxuKxXBoEa7rM12mYLMwTacLMLDJqHozw96WQL8i\"),\n",
    "            (df['cash'] == \"Cvvh8nsKZet59nsDDo3orMa3rZnPWQhpgrMCVcRDRgip\"),\n",
    "            (df['cash'] == \"EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v\"),\n",
    "        ]\n",
    "\n",
    "    # relabeling addresses as asset labels\n",
    "    cash_Categories = [\"UST\", \"tsUSDC\", \"USDC\"]\n",
    "    df['cash'] = np.select(cash_conditions, cash_Categories)\n",
    "    # remove non-stablecoin assets\n",
    "    df = df[df[\"cash\"] != \"0\"]\n",
    "    \n",
    "    # Volt 02 SOL Put: 6Nkc8MEiz3WLz1xthYitmSuy3NGwn7782upRHo2iFmXK\n",
    "    # Volt 02 BTC Put: GrB6vbG2WP7eEnbwgxUbBGRMeXYq139jo2o9oW8cNK8f\n",
    "    # Volt 02 SOL Put (tsUSDC): AQRGh6PU7LzDHvvoPNS7wVVQaCBeftw9kVDAnvuEjbs8\n",
    "    # Volt 02 ETH Put: EA29Xf3HGMtYziw7UKZDUKby7gkoCbXwmiNKwc7z54Ax\n",
    "    # Volt 02 LUNA Put: 5kA7FPiB3t2X5s65dK1AoEu5asDjC5d7f5vaB4iY2yrj\n",
    "    # Volt 02 MNGO Put: CVrRw6VtxSjokm2tKmaS5RCuoc9EFjN4wEoov6f2PST6\n",
    "    \n",
    "    asset_conditions = [\n",
    "            (df['asset'] == \"6Nkc8MEiz3WLz1xthYitmSuy3NGwn7782upRHo2iFmXK\"),\n",
    "            (df['asset'] == \"GrB6vbG2WP7eEnbwgxUbBGRMeXYq139jo2o9oW8cNK8f\"),\n",
    "            (df['asset'] == \"AQRGh6PU7LzDHvvoPNS7wVVQaCBeftw9kVDAnvuEjbs8\"),\n",
    "            (df['asset'] == \"EA29Xf3HGMtYziw7UKZDUKby7gkoCbXwmiNKwc7z54Ax\"),\n",
    "            (df['asset'] == \"5kA7FPiB3t2X5s65dK1AoEu5asDjC5d7f5vaB4iY2yrj\"),\n",
    "            (df['asset'] == \"CVrRw6VtxSjokm2tKmaS5RCuoc9EFjN4wEoov6f2PST6\"),\n",
    "        ]\n",
    "\n",
    "    # relabeling addresses as asset labels\n",
    "    asset_Categories = [\"SOL\", \"BTC\", \"SOL (tsUSDC)\", \"ETH\", \"LUNA\", \"MNGO\"]\n",
    "    df['asset'] = np.select(asset_conditions, asset_Categories)\n",
    "    \n",
    "    \n",
    "    # save into csv\n",
    "    if not csv_files:\n",
    "        df.to_csv(\"volt02_master_wd.csv\")\n",
    "        print(\"Volt 02 Master sheet withdrawal created with dates between \" + query_date)\n",
    "    else:\n",
    "        df.to_csv(\"volt02_master_wd.csv\", mode='a', header=False)\n",
    "        print(\"Volt 02 Master sheet withdrawal created with dates Updated!\") \n",
    "    \n",
    "    # read csv\n",
    "    df_wd = pd.read_csv(\"volt02_master_wd.csv\", index_col=0)\n",
    "    \n",
    "    # drop redundant columns\n",
    "    df_wd.drop(['symbol', 'signer', 'receiver'], axis=1, inplace=True)\n",
    "    df_wd['date'] = pd.to_datetime(df_wd['date'], format = '%Y-%m-%dT%H:%M:%SZ')\n",
    "    # groupby date in grps of 1 week & sum amount of each asset\n",
    "    df_wd = df_wd.groupby([pd.Grouper(key='date', freq='7D'),'asset']).sum()\n",
    "    # Adding Epoch labels per week\n",
    "    df_wd = df_wd.reset_index()\n",
    "    date_df = pd.DataFrame(df_wd['date'].unique())\n",
    "    epoch_lst = []\n",
    "    for i in range(len(date_df)):\n",
    "        epoch_lst.append('Epoch ' + str(i + 1) + ' - ' + str(date_df[0][i].strftime('%Y-%m-%d')))\n",
    "\n",
    "    epoch_df = pd.DataFrame(list(zip(date_df[0], epoch_lst)), columns =['date', 'epoch'])\n",
    "    merge_on_date = pd.merge(epoch_df, df_wd[[\"date\",\"amount\",\"asset\"]], on=\"date\")\n",
    "    merge_on_date['amt_usd'] = merge_on_date['amount'] * 1\n",
    "    merge_on_date\n",
    "    # save df to csv\n",
    "    merge_on_date.to_csv(\"volt02_wd.csv\")\n",
    "    print(\"volt02_wd.csv Updated with date range \" + query_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97a14685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If want files to be immediately generated for date range 17-30 Dec 22, use below lines. \n",
    "# Repeat again to generate data to latest date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df064a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volt01_master.csv missing\n"
     ]
    }
   ],
   "source": [
    "# Will need to manually keep in date range under query_date if run into errors\n",
    "extract_volt_data(\"volt01_master.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9501d851",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_volt_data(\"volt01_master_wd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308cf762",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_volt_data(\"volt02_master.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b972d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_volt_data(\"volt02_master_wd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c54f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If prefer to set a schedule for updating, below will run everyday at a certain time of your specification. \n",
    "# Leaving 2 minutes inbetween each function \n",
    "# when using .do, argument within function is placed in the following manner\n",
    "schedule.every().day.at(\"12:04\").do(extract_volt_data, \"volt01_master.csv\")\n",
    "schedule.every().day.at(\"12:06\").do(extract_volt_data, \"volt01_master_wd.csv\")\n",
    "schedule.every().day.at(\"12:08\").do(extract_volt_data, \"volt02_master.csv\")\n",
    "schedule.every().day.at(\"12:10\").do(extract_volt_data, \"volt02_master_wd.csv\")\n",
    "\n",
    "while True:\n",
    "    # Checks whether a scheduled task \n",
    "    # is pending to run or not\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231dd64b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
